

# GP-Nystagmus Eye Tracking & Training System

A Unity-based interactive eye-tracking and training platform designed to aid individuals with oculomotor disordersâ€”such as nystagmusâ€”by improving gaze fixation through gamified visual engagement.

---

## ğŸ¯ Project Overview

This project combines computer vision and interactive gameplay to monitor and improve eye movement control. The user is guided to follow a moving train on-screen while a webcam captures and records eye movement data. This data is later analyzed using deep learning techniques (CNNs) to evaluate progress and diagnose potential disorders.

---

## ğŸ“‚ Project Resources

* ğŸ“… [Gantt Chart & Timeline](https://docs.google.com/spreadsheets/d/1TkLX_q5t6vAm9R57QAuC5okDFoFYQ8wd57yXewiJa3M/edit?usp=sharing)
* ğŸ“‹ Surveys:

  * [Patient Survey â€“ Arabic](https://docs.google.com/forms/d/e/1FAIpQLSfhU_CxO59pTOpdHfrxsELWIn-23gpyVego-ujayt2F48EqSg/viewform)
  * [Patient Survey â€“ English](https://forms.gle/nXjsG7GL7pAjySASA)
  * [Doctor Survey](https://docs.google.com/forms/d/e/1FAIpQLSciKyrwdtClstPlHFf0jYcR8N-ioTminI9EbtT88zsERKBKZg/viewform)

---

## ğŸ® Game Modes

Two training modules are available:

* ğŸ”— [Full Train Mode](https://drive.google.com/file/d/1_lrU5ZZ7M_gU2Fe3pQ_poHGJD09g1Ga6/view?usp=drive_link)
* ğŸ”— [Single Train Mode](https://drive.google.com/file/d/1uQnZRPEIM_3OgR7_sidVaX8bNVZxBI8W/view?usp=drive_link)

Each mode uses a moving train animation to guide the userâ€™s eye movements. The velocity of the train is adjustable to fit the user's condition or training goal.

---

## ğŸ§  System Architecture

![System Architecture](https://github.com/user-attachments/assets/7de2ecc5-b16d-4cc5-b4e7-b312d7f127f5)

---

## ğŸ” Process Flow

![Process Diagram](https://github.com/user-attachments/assets/1502fac5-6160-49bb-bd6f-02e62fb42eb3)

---

## ğŸ“Š How It Works

* Users either **upload a video** for analysis or **play the game in real-time**.
* During gameplay, the webcam captures live eye movements.
* The data is stored, processed, and exported for machine learning analysis.

---

## ğŸ–¼ï¸ Game Snapshots

### Full Train Mode

![Full Train Gameplay](https://github.com/user-attachments/assets/e88a1ea3-178a-4f93-9001-25e3d3edc743)
![Gameplay View 1](https://github.com/user-attachments/assets/1870d759-da74-462f-bde5-db7a476c92c5)
![Gameplay View 2](https://github.com/user-attachments/assets/c719bd25-d1b4-4de2-a418-7ca8258a7538)
![Gameplay View 3](https://github.com/user-attachments/assets/7e6c1f20-1fce-475d-9b43-01978fa4219b)

---

## ğŸ“ Upload Mode

![Upload Videos](https://github.com/user-attachments/assets/8a77392b-bd8f-4082-93c3-9f816c7ab1f3)

---

## ğŸ‘ï¸ Eye-Only Tracking

![Eye Tracking Only](https://github.com/user-attachments/assets/918ef336-7b7b-41e4-ac6c-f8c70c944590)

---

## ğŸ“ˆ Data Collection & Analysis

* All user session data, including time-stamped gaze logs, is exported into Excel format.
* A **Convolutional Neural Network (CNN)** model is applied to the dataset for diagnostic insight.

![Data Analysis](https://github.com/user-attachments/assets/092d6997-75dd-45d1-8052-30825cb1814d)

---

## ğŸ¤ Contribution

Contributions, feedback, and testing support are welcome! Please open an issue or pull request if you'd like to collaborate.

---

## ğŸ“§ Contact

For inquiries, collaboration, or academic interest, feel free to contact via [GitHub](https://github.com/Shehab-Hegab) or the surveys listed above.

---

Would you like me to add badges (e.g., license, platform, tools used) or a table of contents at the top as well?
