



# GP-Nystagmus Eye Tracking & Training System

A Unity-based interactive eye-tracking and training platform designed to aid individuals with oculomotor disorders—such as nystagmus—by improving gaze fixation through gamified visual engagement.

---

## 🎯 Project Overview

This project combines computer vision and interactive gameplay to monitor and improve eye movement control. The user is guided to follow a moving train on-screen while a webcam captures and records eye movement data. This data is later analyzed using deep learning techniques (CNNs) to evaluate progress and diagnose potential disorders.

---

## 📂 Project Resources

* 📅 [Gantt Chart & Timeline](https://docs.google.com/spreadsheets/d/1TkLX_q5t6vAm9R57QAuC5okDFoFYQ8wd57yXewiJa3M/edit?usp=sharing)
* 📋 Surveys:

  * [Patient Survey – Arabic](https://docs.google.com/forms/d/e/1FAIpQLSfhU_CxO59pTOpdHfrxsELWIn-23gpyVego-ujayt2F48EqSg/viewform)
  * [Patient Survey – English](https://forms.gle/nXjsG7GL7pAjySASA)
  * [Doctor Survey](https://docs.google.com/forms/d/e/1FAIpQLSciKyrwdtClstPlHFf0jYcR8N-ioTminI9EbtT88zsERKBKZg/viewform)
[All project](https://drive.google.com/drive/folders/1yotbj4LZoc8uTqlfI9yhxevtTOcXJYLE)
-----

## 🎮 Game Modes

Two training modules are available:

* 🔗 [Full Train Mode](https://drive.google.com/file/d/1_lrU5ZZ7M_gU2Fe3pQ_poHGJD09g1Ga6/view?usp=drive_link)
* 🔗 [Single Train Mode](https://drive.google.com/file/d/1ojR7fiq_VZm6pnLpM2B_Ad2jcESBpvXJ/view?usp=drive_link)

Each mode uses a moving train animation to guide the user’s eye movements. The velocity of the train is adjustable to fit the user's condition or training goal.

---

## 🧠 System Architecture

![System Architecture](https://github.com/user-attachments/assets/7de2ecc5-b16d-4cc5-b4e7-b312d7f127f5)

---

## 🔁 Process Flow

![Process Diagram](https://github.com/user-attachments/assets/1502fac5-6160-49bb-bd6f-02e62fb42eb3)

---

## 📊 How It Works

* Users either **upload a video** for analysis or **play the game in real-time**.
* During gameplay, the webcam captures live eye movements.
* The data is stored, processed, and exported for machine learning analysis.

---

## 🖼️ Game Snapshots

### Full Train Mode

![Full Train Gameplay](https://github.com/user-attachments/assets/e88a1ea3-178a-4f93-9001-25e3d3edc743)
![Gameplay View 1](https://github.com/user-attachments/assets/1870d759-da74-462f-bde5-db7a476c92c5)
![Gameplay View 2](https://github.com/user-attachments/assets/c719bd25-d1b4-4de2-a418-7ca8258a7538)
![Gameplay View 3](https://github.com/user-attachments/assets/7e6c1f20-1fce-475d-9b43-01978fa4219b)

---

## 📁 Upload Mode

![Upload Videos](https://github.com/user-attachments/assets/8a77392b-bd8f-4082-93c3-9f816c7ab1f3)

---

## 👁️ Eye-Only Tracking

![Eye Tracking Only](https://github.com/user-attachments/assets/918ef336-7b7b-41e4-ac6c-f8c70c944590)

---

## 📈 Data Collection & Analysis

* All user session data, including time-stamped gaze logs, is exported into Excel format.
* A **Convolutional Neural Network (CNN)** model is applied to the dataset for diagnostic insight.

![Data Analysis](https://github.com/user-attachments/assets/092d6997-75dd-45d1-8052-30825cb1814d)

---

## 🤝 Contribution

Contributions, feedback, and testing support are welcome! Please open an issue or pull request if you'd like to collaborate.

---

## 📧 Contact

For inquiries, collaboration, or academic interest, feel free to contact via [GitHub](https://github.com/Shehab-Hegab) or the surveys listed above.

---

Would you like me to add badges (e.g., license, platform, tools used) or a table of contents at the top as well?

# GP-Nystagmus-Eye-Tracking-Training

Eye Tracking and Training Game to train and improve eye gaze, especially in people with Gaze-Fixation issues or Oculomotor Disorders.

Access all associated resources/uploads below:

* [Gantt Chart & Timeline](https://docs.google.com/spreadsheets/d/1TkLX_q5t6vAm9R57QAuC5okDFoFYQ8wd57yXewiJa3M/edit?usp=sharing)
* Surveys - one for [Patients (Arabic)](https://docs.google.com/forms/d/e/1FAIpQLSfhU_CxO59pTOpdHfrxsELWIn-23gpyVego-ujayt2F48EqSg/viewform), another for [Patients (English)](https://forms.gle/nXjsG7GL7pAjySASA), & one for [Doctors](https://docs.google.com/forms/d/e/1FAIpQLSciKyrwdtClstPlHFf0jYcR8N-ioTminI9EbtT88zsERKBKZg/viewform)

##

# You will find two game models available through this link.

* [Full train](https://drive.google.com/file/d/1_lrU5ZZ7M_gU2Fe3pQ_poHGJD09g1Ga6/view?usp=drive_link)
* [Single train](https://drive.google.com/file/d/1uQnZRPEIM_3OgR7_sidVaX8bNVZxBI8W/view?usp=drive_link)

##

By tracking the movement of the train, the camera captures precise eye movement data, enabling the detection of potential vision issues or disorders such as nystagmus. Additionally, the train's velocity can be adjusted to facilitate tailored rehabilitation programs for specific eye conditions.

##

# system architecture

![Shehab (5)](https://github.com/user-attachments/assets/7de2ecc5-b16d-4cc5-b4e7-b312d7f127f5)

##

# process diagram

![image](https://github.com/user-attachments/assets/1502fac5-6160-49bb-bd6f-02e62fb42eb3)

##

# Full Train

![WhatsApp Image 2024-11-30 at 15 57 42\_41eb9ca0](https://github.com/user-attachments/assets/e88a1ea3-178a-4f93-9001-25e3d3edc743)

![WhatsApp Image 2024-11-30 at 15 45 43\_6e4a1e93](https://github.com/user-attachments/assets/1870d759-da74-462f-bde5-db7a476c92c5)

![image](https://github.com/user-attachments/assets/c719bd25-d1b4-4de2-a418-7ca8258a7538)

![image](https://github.com/user-attachments/assets/7e6c1f20-1fce-475d-9b43-01978fa4219b)

![image](https://github.com/user-attachments/assets/64cfd325-3fb2-476a-8001-76bc5a6a9a54)

![image](https://github.com/user-attachments/assets/2914c7b7-351a-48a4-b3b8-8300d532151f)

![image](https://github.com/user-attachments/assets/7b1ee11d-1a4e-4cf9-b47c-f731e8e0fb66)

![image](https://github.com/user-attachments/assets/6c5072b5-b5ce-472d-a7b0-9df170daea3d)

##

You can upload a video for analysis, and we will provide detailed data, or alternatively, you can play the game in real-time. During gameplay, you'll be asked to track the train, and the camera will activate, capturing your eye movements and recording the data in a file for further analysis.

##

![image](https://github.com/user-attachments/assets/0efa7c91-05aa-41e1-abfb-bac942001921)

##

# Upload videos

![image](https://github.com/user-attachments/assets/8a77392b-bd8f-4082-93c3-9f816c7ab1f3)

# eye only

![image](https://github.com/user-attachments/assets/918ef336-7b7b-41e4-ac6c-f8c70c944590)

##

![image](https://github.com/user-attachments/assets/61c0f74b-25c9-44e2-873d-b0f7a6afbbd5)

##

All patient data, including their test histories and timestamps down to hours and seconds, will be consolidated into a single Excel file, and a Convolutional Neural Network (CNN) will be applied to analyze the data.

##

![image](https://github.com/user-attachments/assets/092d6997-75dd-45d1-8052-30825cb1814d)



![WhatsApp Image 2025-06-12 at 20 52 00_4c61e718](https://github.com/user-attachments/assets/07f905d1-d35b-4cf5-b772-ea066cde9900)







![WhatsApp Image 2025-06-12 at 20 52 34_7f5443be](https://github.com/user-attachments/assets/62e0bde9-637d-4508-bf5d-7512f558b505)
![WhatsApp Image 2025-06-12 at 21 19 31_6d84fd56](https://github.com/user-attachments/assets/b7bc01ce-d7ab-497f-91f3-d82b43809e9b)
![WhatsApp Image 2025-06-12 at 21 20 39_e4922c16](https://github.com/user-attachments/assets/f2e2468a-0426-4082-9cb8-f926df8252fa)


![WhatsApp Image 2025-06-12 at 22 39 37_7bffa3fa](https://github.com/user-attachments/assets/d268187b-d2a9-4113-b6fe-cd77c8ae6cec)

![WhatsApp Image 2025-06-12 at 22 40 03_e69abe84](https://github.com/user-attachments/assets/a8f77591-5252-489b-81ea-94df2618481d)

##




![SignalPlot_20250615_175405](https://github.com/user-attachments/assets/e1ff3bf8-60c6-4505-a5ac-28232e8ba544)



![SignalPlot_20250615_173523](https://github.com/user-attachments/assets/73c6e15a-ea34-4eb8-87dc-63c96ae91409)

![SignalPlot_20250615_174734](https://github.com/user-attachments/assets/f9205721-649c-4c1d-b96a-087f08d58ecb)




##





##
# GP-Nystagmus Eye Tracking & Training System

[![Unity](https://img.shields.io/badge/Platform-Unity-ffb400?logo=unity)]()
[![Python](https://img.shields.io/badge/Backend-Python-blue?logo=python)]()
[![License](https://img.shields.io/github/license/Shehab-Hegab/GP-nystagmus-with-eye-tracking)]()

A real-time, interactive **eye-tracking and training system** designed in Unity, with backend analysis powered by deep learning models. The system supports patients with **oculomotor disorders** such as **nystagmus** by enhancing their gaze fixation through visual training games.

---

## 📚 Table of Contents

- [🎯 Project Overview](#-project-overview)
- [📂 Project Resources](#-project-resources)
- [🎮 Game Modes](#-game-modes)
- [🧠 System Architecture](#-system-architecture)
- [🔁 Process Flow](#-process-flow)
- [📊 How It Works](#-how-it-works)
- [🖼️ Gameplay Snapshots](#-gameplay-snapshots)
- [📁 Upload Mode](#-upload-mode)
- [👁️ Eye-Only Tracking](#-eye-only-tracking)
- [📈 Data Collection & Analysis](#-data-collection--analysis)
- [🤝 Contribution](#-contribution)
- [📧 Contact](#-contact)

---

## 🎯 Project Overview

This project merges **computer vision**, **machine learning**, and **interactive Unity gameplay** to assist individuals with gaze-fixation difficulties.

During gameplay, users are asked to follow a moving train with their eyes. A camera captures and logs their eye movements in real time. The data is then analyzed using **Convolutional Neural Networks (CNNs)** to detect irregularities and measure improvement.

---

## 📂 Project Resources

- 📅 [Gantt Chart & Timeline](https://docs.google.com/spreadsheets/d/1TkLX_q5t6vAm9R57QAuC5okDFoFYQ8wd57yXewiJa3M/edit?usp=sharing)
- 📋 Surveys:
  - [📝 Patient Survey – Arabic](https://docs.google.com/forms/d/e/1FAIpQLSfhU_CxO59pTOpdHfrxsELWIn-23gpyVego-ujayt2F48EqSg/viewform)
  - [📝 Patient Survey – English](https://forms.gle/nXjsG7GL7pAjySASA)
  - [🩺 Doctor Survey](https://docs.google.com/forms/d/e/1FAIpQLSciKyrwdtClstPlHFf0jYcR8N-ioTminI9EbtT88zsERKBKZg/viewform)

---

## 🎮 Game Modes

Two game modes are available:

- 🚆 [Full Train Mode](https://drive.google.com/file/d/1_lrU5ZZ7M_gU2Fe3pQ_poHGJD09g1Ga6/view?usp=drive_link)
- 🚈 [Single Train Mode](https://drive.google.com/file/d/1uQnZRPEIM_3OgR7_sidVaX8bNVZxBI8W/view?usp=drive_link)

> 🧭 The train’s speed is adjustable based on the patient's condition, providing adaptive difficulty for different therapy stages.

---

## 🧠 System Architecture

![System Architecture](https://github.com/user-attachments/assets/7de2ecc5-b16d-4cc5-b4e7-b312d7f127f5)

---

## 🔁 Process Flow

![Process Diagram](https://github.com/user-attachments/assets/1502fac5-6160-49bb-bd6f-02e62fb42eb3)

---

## 📊 How It Works

- 🧪 **Data Collection**: Real-time camera captures eye movement.
- 🎮 **Game Interaction**: Patient follows a moving object on-screen.
- 📦 **Data Storage**: Eye movement data saved to Excel format.
- 🧠 **Deep Learning Analysis**: CNN model detects patterns for diagnosis.

---

## 🖼️ Gameplay Snapshots

### 🎥 Full Train Mode

![Full Train Gameplay](https://github.com/user-attachments/assets/e88a1ea3-178a-4f93-9001-25e3d3edc743)
![Gameplay View 1](https://github.com/user-attachments/assets/1870d759-da74-462f-bde5-db7a476c92c5)
![Gameplay View 2](https://github.com/user-attachments/assets/c719bd25-d1b4-4de2-a418-7ca8258a7538)
![Gameplay View 3](https://github.com/user-attachments/assets/7e6c1f20-1fce-475d-9b43-01978fa4219b)
![Gameplay View 4](https://github.com/user-attachments/assets/64cfd325-3fb2-476a-8001-76bc5a6a9a54)
![Gameplay View 5](https://github.com/user-attachments/assets/2914c7b7-351a-48a4-b3b8-8300d532151f)
![Gameplay View 6](https://github.com/user-attachments/assets/7b1ee11d-1a4e-4cf9-b47c-f731e8e0fb66)
![Gameplay View 7](https://github.com/user-attachments/assets/6c5072b5-b5ce-472d-a7b0-9df170daea3d)

---

## 📁 Upload Mode

Upload a recorded video for offline analysis. The system will extract eye movement data and produce plots and analytics.

![Upload Videos](https://github.com/user-attachments/assets/8a77392b-bd8f-4082-93c3-9f816c7ab1f3)

---

## 👁️ Eye-Only Tracking

This mode isolates and tracks the user's eyes without the surrounding facial context.

![Eye Tracking Only](https://github.com/user-attachments/assets/918ef336-7b7b-41e4-ac6c-f8c70c944590)
![Eye Plot](https://github.com/user-attachments/assets/61c0f74b-25c9-44e2-873d-b0f7a6afbbd5)

---

## 📈 Data Collection & Analysis

- Eye movement sessions are saved as Excel files with millisecond-level timestamps.
- A **CNN model** is trained on the gaze data to detect irregularities.
- Data is visualized for easy interpretation by clinicians or researchers.

![Data Graph](https://github.com/user-attachments/assets/092d6997-75dd-45d1-8052-30825cb1814d)
![Graph 2](https://github.com/user-attachments/assets/07f905d1-d35b-4cf5-b772-ea066cde9900)
![Graph 3](https://github.com/user-attachments/assets/62e0bde9-637d-4508-bf5d-7512f558b505)
![Graph 4](https://github.com/user-attachments/assets/b7bc01ce-d7ab-497f-91f3-d82b43809e9b)
![Graph 5](https://github.com/user-attachments/assets/f2e2468a-0426-4082-9cb8-f926df8252fa)
![Graph 6](https://github.com/user-attachments/assets/d268187b-d2a9-4113-b6fe-cd77c8ae6cec)
![Graph 7](https://github.com/user-attachments/assets/e1ff3bf8-60c6-4505-a5ac-28232e8ba544)
![Graph 8](https://github.com/user-attachments/assets/a8f77591-5252-489b-81ea-94df2618481d)
![Graph 9](https://github.com/user-attachments/assets/73c6e15a-ea34-4eb8-87dc-63c96ae91409)
![Graph 10](https://github.com/user-attachments/assets/f9205721-649c-4c1d-b96a-087f08d58ecb)

---


##
for gaze fixation game 


![image](https://github.com/user-attachments/assets/866840e4-0804-474b-bd45-6c6eb1e5a392)

![image](https://github.com/user-attachments/assets/70d847cf-04b9-4bfd-bd50-b19bfb3dcdff)
![image](https://github.com/user-attachments/assets/87c3b1b7-f9c2-405a-8bf0-3b79293406d3)

![image](https://github.com/user-attachments/assets/b447d3c5-0600-4cfa-990e-dc0f3b0a0ee3)

![image](https://github.com/user-attachments/assets/73a7e3e5-22a4-4291-ac75-34caa421ecfb)

![Screenshot 2025-06-21 213221](https://github.com/user-attachments/assets/fc21dd9c-8cbd-43d7-aff9-6a273a067a1b)

![image](https://github.com/user-attachments/assets/5ccab184-62ab-46ef-8305-b72bcaedd89e)

![image](https://github.com/user-attachments/assets/ffc51250-16c6-4213-bcc3-179cdbea6ecf)

![image](https://github.com/user-attachments/assets/4346c7d6-7cd2-4768-bcd0-bd6c2a9f5c14)
![image](https://github.com/user-attachments/assets/891c4d67-2739-4114-9b88-8cf4f2f270c7)


![Screenshot 2025-07-08 210658](https://github.com/user-attachments/assets/e1582d77-0a94-4b24-bbe7-40387f919bb9)

![Screenshot 2025-07-08 211059](https://github.com/user-attachments/assets/097c3714-1e8b-4ddf-821c-a1d22ca2c06d)

![Screenshot 2025-07-08 211126](https://github.com/user-attachments/assets/147f283c-a50d-4f66-8b08-5cb2584a0a4e)


## 🤝 Contribution

We welcome collaboration, feedback, and contributions!  
Feel free to:

- Submit bug reports or feature requests via **GitHub Issues**
- Fork the repo and open a **Pull Request** for improvements or experiments

---

## 📧 Contact

For research inquiries, academic collaboration, or technical questions, please reach out via:

- 💼 [GitHub Profile](https://github.com/Shehab-Hegab)
- 📝 [Surveys and Contact Forms](#-project-resources)

---

> _This project was developed as part of a graduation thesis exploring the intersection of assistive technology, human-computer interaction, and biomedical AI._

